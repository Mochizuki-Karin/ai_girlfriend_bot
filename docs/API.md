# AIã‚¬ãƒ¼ãƒ«ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒœãƒƒãƒˆ - APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯AIã‚¬ãƒ¼ãƒ«ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒœãƒƒãƒˆã®å†…éƒ¨APIã¨æ‹¡å¼µã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

## ç›®æ¬¡

1. [è¨­å®š API](#è¨­å®š-api)
2. [å¥½æ„Ÿåº¦ã‚·ã‚¹ãƒ†ãƒ  API](#å¥½æ„Ÿåº¦ã‚·ã‚¹ãƒ†ãƒ -api)
3. [ãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ  API](#ãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ -api)
4. [çŸ¥è­˜ã‚·ã‚¹ãƒ†ãƒ  API](#çŸ¥è­˜ã‚·ã‚¹ãƒ†ãƒ -api)
5. [LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ API](#llmã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ-api)
6. [ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ API](#ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ-api)

---

## è¨­å®š API

### PersonaConfig

äººæ ¼è¨­å®šãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã€‚

```python
from src.config import PersonaConfig

# äººæ ¼ã‚’èª­ã¿è¾¼ã¿
persona = PersonaConfig("config/persona_default.yaml")

# åŸºæœ¬æƒ…å ±ã‚’å–å¾—
name = persona.basic_info['name']  # "ã•ãã‚‰"
age = persona.basic_info['age']    # 22

# æ€§æ ¼ã®èª¬æ˜ã‚’å–å¾—
description = persona.personality['description']

# è©±ã—æ–¹ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å–å¾—
speech_style = persona.speech_style

# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
system_prompt = persona.get_system_prompt()

# è¨­å®šã‚’å†èª­ã¿è¾¼ã¿
persona.reload()
```

### Settings

ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã€‚

```python
from src.config import settings

# Telegramè¨­å®š
token = settings.telegram_bot_token

# LLMè¨­å®š
llm_provider = settings.llm.default_provider
openai_model = settings.llm.openai_model

# è¡Œå‹•è¨­å®š
affection_enabled = settings.behavior.affection_enabled
memory_enabled = settings.behavior.memory_enabled
```

---

## å¥½æ„Ÿåº¦ã‚·ã‚¹ãƒ†ãƒ  API

### AffectionSystem

```python
from src.affection_system import AffectionSystem

# åˆæœŸåŒ–
affection = AffectionSystem("./data")

# ãƒ¦ãƒ¼ã‚¶ãƒ¼çŠ¶æ…‹ã‚’å–å¾—
state = affection.get_state("user_123")
print(state.score)        # å¥½æ„Ÿåº¦ã‚¹ã‚³ã‚¢
print(state.current_mood) # ç¾åœ¨ã®æ„Ÿæƒ…

# é–¢ä¿‚ãƒ¬ãƒ™ãƒ«ã‚’å–å¾—
level = affection.get_level("user_123")
# AffectionLevel.FRIEND, AffectionLevel.LOVER, etc.

# å¥½æ„Ÿåº¦ã‚’æ›´æ–°
new_score, feedback = affection.update(
    "user_123",
    action="compliment",  # è¤’ã‚ã‚‹
    context={}
)

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†
new_score, feedback, actions = affection.process_message(
    "user_123",
    message="ã‚ãªãŸã¯ä»Šæ—¥ã¨ã¦ã‚‚ç¶ºéº—ã ",
    response_time_seconds=30
)

# é–¢ä¿‚çŠ¶æ…‹ã‚’å–å¾—
status = affection.get_relationship_status("user_123")
# {
#     'score': 75.5,
#     'level': 'ç‰‡æ€ã„',
#     'next_level': 'æ‹äºº',
#     'progress_to_next': 37.0,
#     'mood': 'happy',
#     'interaction_count': 150
# }

# æ„Ÿæƒ…ã‚’è¨­å®š
affection.set_mood("user_123", "happy", intensity=0.8, reason="ãƒ—ãƒ¬ã‚¼ãƒ³ãƒˆã‚’ã‚‚ã‚‰ã£ãŸ")

# ç‰¹åˆ¥ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¿½åŠ 
affection.add_special_event("user_123", "first_date", "åˆã‚ã¦ã®ãƒ‡ãƒ¼ãƒˆ")

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¼·åŒ–ã®ãƒ’ãƒ³ãƒˆã‚’å–å¾—
hint = affection.get_affection_hint_for_prompt("user_123")
```

### AffectionLevel

```python
from src.affection_system import AffectionLevel

# ç­‰ç´šåˆ—æŒ™
AffectionLevel.STRANGER      # 0-10
AffectionLevel.ACQUAINTANCE  # 10-30
AffectionLevel.FRIEND        # 30-50
AffectionLevel.CLOSE_FRIEND  # 50-70
AffectionLevel.CRUSH         # 70-85
AffectionLevel.LOVER         # 85-95
AffectionLevel.SOULMATE      # 95-100

# ç­‰ç´šã‚’å–å¾—
level = AffectionLevel.get_level(75.5)  # AffectionLevel.CRUSH

# ç­‰ç´šå±æ€§
print(level.level_name)  # "è¦‹çŸ¥ã‚‰ã¬äºº"
print(level.greeting)    # "ã“ã‚“ã«ã¡ã¯"
```

---

## ãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ  API

### MemorySystem

```python
from src.memory_system import MemorySystem
import chromadb

# åˆæœŸåŒ–
chroma_client = chromadb.Client()
memory = MemorySystem(chroma_client, llm_client=None)

# ä¼šè©±ãƒ©ã‚¦ãƒ³ãƒ‰ã‚’å‡¦ç†
await memory.process_conversation_turn(
    user_id="user_123",
    user_message="ç§ã¯ç«é‹ãŒå¥½ã",
    bot_response="ç«é‹ã¯æœ¬å½“ã«ç¾å‘³ã—ã„ã§ã™ã­ï¼",
    emotional_context={"mood": "happy"},
    topics=["food", "hotpot"]
)

# ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
context = await memory.get_context_for_response(
    user_id="user_123",
    current_message="ä»Šæ™©ä½•ã‚’é£Ÿã¹ã‚‹ã‹",
    include_short_term=True,
    include_long_term=True,
    n_long_term=5
)

# æ˜ç¤ºçš„ãªãƒ¡ãƒ¢ãƒªã‚’è¿½åŠ 
await memory.add_explicit_memory(
    user_id="user_123",
    content="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èª•ç”Ÿæ—¥ã¯3æœˆ15æ—¥",
    memory_type="fact",
    importance=0.9
)

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
profile = await memory.get_user_profile("user_123")
# {
#     'facts': ['ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç«é‹ãŒå¥½ã', 'ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èª•ç”Ÿæ—¥ã¯3æœˆ15æ—¥'],
#     'preferences': ['è¾›ã„é£Ÿã¹ç‰©ãŒå¥½ã'],
#     'events': ['åˆãƒ‡ãƒ¼ãƒˆ'],
#     'emotions': ['ãƒ—ãƒ¬ã‚¼ãƒ³ãƒˆã‚’è²°ã£ãŸã¨ãã«å¬‰ã—ã„']
# }

# ãƒ¡ãƒ¢ãƒªã‚’çµ±åˆ
await memory.consolidate("user_123")

# çŸ­æœŸè¨˜æ†¶ã‚’ã‚¯ãƒªã‚¢
memory.clear_short_term("user_123")
```

### ShortTermMemory

```python
from src.memory_system import ShortTermMemory

# åˆæœŸåŒ–
short_term = ShortTermMemory(max_turns=10)

# ä¼šè©±ãƒ©ã‚¦ãƒ³ãƒ‰ã‚’è¿½åŠ 
short_term.add_turn(
    user_id="user_123",
    user_message="ã“ã‚“ã«ã¡ã¯",
    bot_response="ã“ã‚“ã«ã¡ã¯ï½",
    emotional_context={},
    topics=["greeting"]
)

# æœ€è¿‘ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
turns = short_term.get_recent_context("user_123", n_turns=5)

# ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ–‡å­—åˆ—ã‚’å–å¾—
context = short_term.get_context_string("user_123", n_turns=5)

# è­°è«–ã•ã‚ŒãŸãƒˆãƒ”ãƒƒã‚¯ã‚’å–å¾—
topics = short_term.get_topics("user_123", n_turns=10)
```

### LongTermMemory

```python
from src.memory_system import LongTermMemory, Memory

# åˆæœŸåŒ–
long_term = LongTermMemory(chroma_client)

# ãƒ¡ãƒ¢ãƒªã‚’è¿½åŠ 
memory = Memory(
    id="mem_123",
    content="ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒçŒ«ãŒå¥½ã",
    memory_type="preference",
    importance=0.8,
    user_id="user_123"
)
await long_term.add_memory(memory)

# ãƒãƒƒãƒè¿½åŠ 
await long_term.add_memories([memory1, memory2, memory3])

# é–¢é€£ã™ã‚‹ãƒ¡ãƒ¢ãƒªã‚’æ¤œç´¢
memories = await long_term.retrieve_relevant(
    query="ãƒšãƒƒãƒˆ",
    user_id="user_123",
    n_results=5,
    memory_types=["preference", "fact"],
    min_importance=0.5
)

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã™ã¹ã¦ã®ãƒ¡ãƒ¢ãƒªã‚’å–å¾—
all_memories = await long_term.get_user_memories(
    user_id="user_123",
    memory_types=["fact"]
)

# ãƒ¡ãƒ¢ãƒªã‚’å‰Šé™¤
await long_term.delete_memory("mem_123")
```

---

## çŸ¥è­˜ã‚·ã‚¹ãƒ†ãƒ  API

### KnowledgeSystem

```python
from src.knowledge_system import KnowledgeSystem

# åˆæœŸåŒ–
knowledge = KnowledgeSystem(
    chroma_client=chroma_client,
    llm_client=llm_client,
    knowledge_base_path="./data/knowledge",
    persona_config_path="./config/persona_default.yaml"
)

# çŸ¥è­˜ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦å­¦ç¿’
result = await knowledge.import_and_learn(
    source="./docs/about_user.txt",
    source_type="file",  # file, directory, text
    category="personal"
)
# {
#     'imported_count': 10,
#     'insights_count': 5,
#     'insights_by_type': {'preference': 3, 'fact': 2}
# }

# å¼·åŒ–ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
context = await knowledge.get_enhanced_context("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")

# å¯¾è©±ã‹ã‚‰å­¦ç¿’
insights_count = await knowledge.learn_from_conversation(
    user_message="ç§ã¯é’ãŒå¥½ã",
    bot_response="é’ã¯ç¶ºéº—ã§ã™ã­",
    user_id="user_123"
)

# å­¦ç¿’ã‚µãƒãƒªãƒ¼ã‚’å–å¾—
summary = knowledge.get_learning_summary()
# {
#     'total_facts': 15,
#     'total_preferences': 8,
#     'total_patterns': 3,
#     'total_emotional_rules': 2
# }
```

### KnowledgeImporter

```python
from src.knowledge_system import KnowledgeImporter

importer = KnowledgeImporter("./data/knowledge")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
items = await importer.import_file(
    file_path="./docs/info.txt",
    category="general"
)

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
items = await importer.import_directory(
    dir_path="./knowledge_files",
    category="personal"
)

# ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
item = await importer.import_text(
    text="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èª•ç”Ÿæ—¥ã¯3æœˆ15æ—¥",
    source="manual_input",
    category="personal"
)
```

### KnowledgeLearner

```python
from src.knowledge_system import KnowledgeLearner

learner = KnowledgeLearner(llm_client)

# çŸ¥è­˜ã‹ã‚‰å­¦ç¿’
insights = await learner.learn_from_knowledge(items)

# LLMã‚’ä½¿ç”¨ã—ã¦æ·±å±¤å­¦ç¿’
deep_insights = await learner.deep_learn_with_llm(items)
```

### KnowledgeIntegrator

```python
from src.knowledge_system import KnowledgeIntegrator

integrator = KnowledgeIntegrator("./config/persona_default.yaml")

# æ´å¯Ÿã‚’ personality ã«çµ±åˆ
await integrator.integrate_insights(insights)

# å¼·åŒ–ã•ã‚ŒãŸã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
enhanced_prompt = integrator.get_enhanced_system_prompt(base_prompt)
```

### KnowledgeRetriever

```python
from src.knowledge_system import KnowledgeRetriever

retriever = KnowledgeRetriever(chroma_client)

# çŸ¥è­˜ã‚’ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ 
await retriever.add_knowledge(items)

# é–¢é€£ã™ã‚‹çŸ¥è­˜ã‚’æ¤œç´¢
items = await retriever.retrieve_relevant(
    query="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿",
    n_results=5,
    min_similarity=0.5
)

# å¯¾è©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
context = await retriever.get_context_for_conversation(
    user_message="ä½•ãŒå¥½ãã§ã™ã‹",
    conversation_history=[]
)
```

---

## LLM ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ API

### LLMClientManager

```python
from src.llm_client import create_llm_manager, LLMConfig

# è¨­å®šã‹ã‚‰ä½œæˆ
llm_manager = create_llm_manager(settings)

# æ–°ã—ã„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ç™»éŒ²
llm_manager.register_client(
    name="custom",
    client=CustomLLMClient(config),
    is_default=False
)

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
client = llm_manager.get_client("openai")

# ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ
response = await llm_manager.generate(
    prompt="ã“ã‚“ã«ã¡ã¯",
    provider="openai",
    system_prompt="ã‚ãªãŸã¯ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™",
    temperature=0.7,
    max_tokens=500
)
print(response.content)
print(response.usage)

# å¯¾è©±ç”Ÿæˆ
response = await llm_manager.chat(
    messages=[
        {"role": "system", "content": "ã‚ãªãŸã¯ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™"},
        {"role": "user", "content": "ã“ã‚“ã«ã¡ã¯"}
    ],
    provider="openai"
)

# ã™ã¹ã¦ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’é–‰ã˜ã‚‹
await llm_manager.close_all()
```

### ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”Ÿæˆ

```python
# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”Ÿæˆ
async for chunk in client.generate_stream(
    prompt="ç‰©èªã‚’èªã£ã¦",
    system_prompt="ã‚ãªãŸã¯ç‰©èªã‚’èªã‚‹äººã§ã™"
):
    print(chunk, end="")

# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾è©±
async for chunk in client.chat_stream(messages):
    print(chunk, end="")
```

### ã‚«ã‚¹ã‚¿ãƒ  LLM ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

```python
from src.llm_client import BaseLLMClient, LLMResponse, LLMConfig

class CustomLLMClient(BaseLLMClient):
    async def generate(self, prompt, system_prompt=None, **kwargs):
        # ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…
        content = await self._call_api(prompt, system_prompt)
        
        return LLMResponse(
            content=content,
            model=self.config.model,
            usage={"prompt_tokens": 10, "completion_tokens": 20},
            finish_reason="stop"
        )
    
    async def generate_stream(self, prompt, system_prompt=None, **kwargs):
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”Ÿæˆã‚’å®Ÿè£…
        async for chunk in self._call_streaming_api(prompt):
            yield chunk
    
    async def chat(self, messages, **kwargs):
        # å¯¾è©±ç”Ÿæˆã‚’å®Ÿè£…
        pass

# ç™»éŒ²
config = LLMConfig(provider="custom", api_key="xxx", model="custom-model")
llm_manager.register_client("custom", CustomLLMClient(config))
```

---

## ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ API

### MessageGenerator

```python
from src.message_generator import MessageGenerator

generator = MessageGenerator(
    llm_manager=llm_manager,
    affection_system=affection_system,
    memory_system=memory_system,
    knowledge_system=knowledge_system
)

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ
response, new_affection = await generator.generate_response(
    user_id="user_123",
    user_message="ä»Šæ—¥ã¯ã©ã†ã ã£ãŸ",
    provider="openai"
)

# ä¸»å‹•ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
initiative_msg = await generator.generate_initiative_message(
    user_id="user_123",
    provider="openai"
)

# ä¸»å‹•ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚‹ã¹ãã‹åˆ¤æ–­
should_initiate = generator.should_initiate("user_123")

# ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
typing_params = generator.get_typing_params(
    user_id="user_123",
    message="ã“ã‚Œã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™"
)
# {
#     'speed': 'normal',
#     'thinking_time': 'medium',
#     'duration': 3.5
# }

# éŸ³å£°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ
voice_text = await generator.generate_voice_message_text(
    user_id="user_123",
    emotion="happy"
)
```

### ResponseStyler

```python
from src.message_generator import ResponseStyler
from src.affection_system import AffectionLevel

# èªæ°—è©ã‚’è¿½åŠ 
styled = ResponseStyler.add_particles("ã‚ãªãŸã¯ä»Šæ—¥ã©ã†ã ã£ãŸ", frequency=0.5)
# "ã‚ãªãŸã¯ä»Šæ—¥ã©ã†ã ã£ãŸã­"

# çµµæ–‡å­—ã‚’è¿½åŠ 
styled = ResponseStyler.add_emojis("ä»Šæ—¥ã®å¤©æ°—ã¯è‰¯ã„", frequency=0.5)
# "ä»Šæ—¥ã®å¤©æ°—ã¯è‰¯ã„ğŸ˜Š"

# å®Œå…¨ãªã‚¹ã‚¿ã‚¤ãƒ«ã‚’é©ç”¨
styled = ResponseStyler.apply_style(
    text="ä¼šã„ãŸã„",
    affection_level=AffectionLevel.LOVER
)
# "ä¼šã„ãŸã„ğŸ¥°ï½"
```

---

## ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒƒã‚¯

### ã‚«ã‚¹ã‚¿ãƒ ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†

```python
from src.bot import bot

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‰å‡¦ç†ãƒ•ãƒƒã‚¯ã‚’ç™»éŒ²
async def before_message_hook(user_id, message):
    print(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡: {message}")
    return message

bot.register_hook("before_message", before_message_hook)

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å¾Œå‡¦ç†ãƒ•ãƒƒã‚¯ã‚’ç™»éŒ²
async def after_message_hook(user_id, response):
    print(f"è¿”ä¿¡é€ä¿¡: {response}")
    
bot.register_hook("after_message", after_message_hook)
```

---

## æ‹¡å¼µé–‹ç™º

### ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒãƒ³ãƒ‰ã‚’ä½œæˆ

```python
from telegram import Update
from telegram.ext import ContextTypes

async def custom_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒãƒ³ãƒ‰"""
    user_id = update.effective_user.id
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    state = bot.affection_system.get_state(str(user_id))
    
    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’é€ä¿¡
    await update.message.reply_text(f"ã‚ãªãŸã®å¥½æ„Ÿåº¦: {state.score}")

# ã‚³ãƒãƒ³ãƒ‰ã‚’ç™»éŒ²
bot.application.add_handler(CommandHandler("custom", custom_command))
```

### ã‚«ã‚¹ã‚¿ãƒ äººæ ¼ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’ä½œæˆ

```python
class CustomPersonalityPlugin:
    """ã‚«ã‚¹ã‚¿ãƒ äººæ ¼ãƒ—ãƒ©ã‚°ã‚¤ãƒ³"""
    
    def __init__(self, bot):
        self.bot = bot
    
    def modify_system_prompt(self, base_prompt: str) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿®æ­£"""
        return base_prompt + "\n\nè¿½åŠ æŒ‡ç¤ºï¼š..."
    
    def on_message(self, user_id: str, message: str):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ãƒ•ãƒƒã‚¯"""
        pass
    
    def on_response(self, user_id: str, response: str) -> str:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ãƒ•ãƒƒã‚¯"""
        return response

# ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’ç™»éŒ²
plugin = CustomPersonalityPlugin(bot)
bot.register_plugin(plugin)
```

---

## ã‚ˆã‚Šå¤šãã®ä¾‹

`examples/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã‚ˆã‚Šå¤šãã®ä½¿ç”¨ä¾‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

---

**Happy Coding!** ğŸ¤–ğŸ’•
